{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import recova.learning_dataset\n",
    "import recova.trajectory_evaluation as traj\n",
    "from recova.registration_result_database import RegistrationPairDatabase\n",
    "from recova.learning.learning import model_from_file\n",
    "from recova.util import kullback_leibler, wishart_kl_divergence\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = {\n",
    "    'apartment': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-11-inside.json', \n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-11-apartment.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-11-apartment.model',\n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-11-apartment.json'\n",
    "    ), 'hauptgebaude': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-11-inside.json', \n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-11-hauptgebaude.json', \n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-11-hauptgebaude.model', \n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-11-hauptgebaude.json'\n",
    "    ), 'stairs': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-11-inside.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-11-stairs.json', \n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-11-stairs.model', \n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-11-stairs.json'\n",
    "    ), 'gazebo_summer': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-12-gazebo.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-gazebo-summer.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-gazebo-summer.model',\n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-12-gazebo-summer.json'\n",
    "    ), 'gazebo_winter': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-12-gazebo.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-gazebo-winter.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-gazebo-winter.model',\n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-12-gazebo-winter.json'\n",
    "    ), 'wood_autumn': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-12-wood.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-wood-autumn.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-wood-autumn.model',\n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-12-wood-autumn.json'\n",
    "    ), 'wood_summer': (\n",
    "        '/home/dlandry/dataset/learning_sets/2018-09-12-wood.json',\n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-wood-summer.json', \n",
    "        '/home/dlandry/dataset/learning_runs/2018-09-12-wood-summer.model',\n",
    "        '/home/dlandry/dataset/censi_estimates/2018-09-12-wood-summer.json'\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frobenius_norm(m):\n",
    "    return np.sqrt(np.trace((m).T @ (m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_to_loss(learning_set_file, learning_run_file, model_file, censi_estimates_file):\n",
    "    with open(learning_set_file) as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    with open(learning_run_file) as f:\n",
    "        learning_run = json.load(f)\n",
    "\n",
    "    with open(censi_estimates_file) as f:\n",
    "        censi_estimates = json.load(f)\n",
    "    \n",
    "    model = model_from_file(model_file, 'cello')\n",
    "    \n",
    "    xs = np.array(dataset['data']['xs'])\n",
    "    ys = np.array(dataset['data']['ys'])\n",
    "\n",
    "\n",
    "    train_set = learning_run['train_set']\n",
    "    validation_set = learning_run['validation_set']\n",
    "    \n",
    "    validation_xs = xs[validation_set]\n",
    "    validation_ys = ys[validation_set]\n",
    "\n",
    "    train_ys = ys[train_set]\n",
    "    avg_train_ys = np.mean(train_ys, axis=0)\n",
    "    \n",
    "    predictions = model.predict(validation_xs)\n",
    "    censi_predictions = np.array(censi_estimates['data']['censi_estimates'])\n",
    "    \n",
    "    reference_norms = np.zeros(len(predictions))\n",
    "    prediction_norms = np.zeros(len(predictions))\n",
    "    norm_loss = np.zeros(len(predictions))\n",
    "    gaussian_kl = np.zeros(len(predictions))\n",
    "    percent_loss = np.zeros(len(predictions))\n",
    "    censi_loss = np.zeros(len(predictions))\n",
    "    censi_kl = np.zeros(len(predictions))\n",
    "    baseline_loss = np.zeros(len(predictions))\n",
    "    baseline_kl = np.zeros(len(predictions))\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        reference_norms[i] = np.linalg.norm(ys[validation_set[i]])\n",
    "        prediction_norms[i] = np.linalg.norm(predictions[i])\n",
    "        norm_loss[i] = frobenius_norm(ys[validation_set[i]] - predictions[i])\n",
    "        percent_loss = abs(norm_loss[i] / np.linalg.norm(ys[validation_set[i]]))\n",
    "        gaussian_kl[i] = kullback_leibler(ys[validation_set[i]], predictions[i])\n",
    "\n",
    "        censi_loss[i] = frobenius_norm(ys[validation_set[i]] - censi_predictions[i])\n",
    "        censi_kl[i] = kullback_leibler(ys[validation_set[i]], censi_predictions[i])\n",
    "\n",
    "        baseline_loss[i] = frobenius_norm(ys[validation_set[i]] - avg_train_ys)\n",
    "        baseline_kl[i] = kullback_leibler(ys[validation_set[i]], avg_train_ys)\n",
    "            \n",
    "    print('{}, {}, {:.3f}, {:.3f}, {:.2E}'.format(\n",
    "        learning_run['metadata']['cross_validation'],\n",
    "        len(predictions),\n",
    "        baseline_kl.mean(),\n",
    "        gaussian_kl.mean(),\n",
    "        censi_kl.mean()\n",
    "    ))\n",
    "        \n",
    "    print()\n",
    "    print()\n",
    "    print('Dataset: {}'.format(learning_run['metadata']['cross_validation']))\n",
    "    print('N Pairs: {}'.format(len(predictions)))\n",
    "\n",
    "    print('Avg. Percent loss: {:.2E}'.format(percent_loss.mean()))\n",
    "    print()\n",
    "    print('Avg. Baseline loss: {:.4E}'.format(baseline_loss.mean()))\n",
    "    print('Avg. Baseline KL: {:.2f}'.format(baseline_kl.mean()))\n",
    "    print()\n",
    "    print('Avg. loss: {:.2E}'.format(norm_loss.mean()))\n",
    "    print('Avg. KL loss: {:.2f}'.format(gaussian_kl.mean()))\n",
    "    print()\n",
    "    print('Avg. Censi Loss: {:.2E}'.format(censi_loss.mean()))\n",
    "    print('Avg. Censi KL loss: {:.2E}'.format(censi_kl.mean()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dispersion_of_model(model_file):\n",
    "    model = model_from_file(model_file, 'cello')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispersion of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_from_file(locations['apartment'][2], 'cello')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012994935736060143"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta.std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03357156366109848"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta_to_metric_matrix(model.theta).std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apartment    : 0.033572\n",
      "gazebo_summer: 0.002597\n",
      "gazebo_winter: 0.003647\n",
      "hauptgebaude : 0.036582\n",
      "stairs       : 0.036103\n",
      "wood_autumn  : 0.018713\n",
      "wood_summer  : 0.018524\n"
     ]
    }
   ],
   "source": [
    "for loc in sorted(locations):\n",
    "    model = model_from_file(locations[loc][2], 'cello')\n",
    "    \n",
    "    print('{:<13}: {:03f}'.format(loc, model.theta_to_metric_matrix(model.theta).std().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wood_summer, 966, 13.607, 11.287, 3.52E+07\n",
      "\n",
      "\n",
      "Dataset: wood_summer\n",
      "N Pairs: 966\n",
      "Avg. Percent loss: 8.58E-01\n",
      "\n",
      "Avg. Baseline loss: 2.6320E-02\n",
      "Avg. Baseline KL: 13.61\n",
      "\n",
      "Avg. loss: 2.00E-02\n",
      "Avg. KL loss: 11.29\n",
      "\n",
      "Avg. Censi Loss: 2.07E-02\n",
      "Avg. Censi KL loss: 3.52E+07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_to_loss(*locations['wood_summer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
